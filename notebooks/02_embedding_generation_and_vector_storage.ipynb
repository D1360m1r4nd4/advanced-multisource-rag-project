{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99528bf9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "407aa602",
   "metadata": {},
   "source": [
    "# Notebook 02 Embedding and Qdrant Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1ba4cb",
   "metadata": {},
   "source": [
    "# 1 Setup & Imports\n",
    "\n",
    "This notebook connects processed data (chunks.jsonl)\n",
    "with an open-source embeddings model and Qdrant vector DB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d15db0be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using chunks file: ./data/chunks.jsonl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm  # Progress bar for embedding generation\n",
    "from typing import List, Dict\n",
    "\n",
    "# SentenceTransformers provides pre-trained embedding models.\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Qdrant client library — connects to your local or remote Qdrant instance.\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http import models as rest\n",
    "\n",
    "# Paths \n",
    "DATA_DIR = \"./data\"\n",
    "CHUNKS_FILE = os.path.join(DATA_DIR, \"chunks.jsonl\")\n",
    "\n",
    "\n",
    "# Sanity check \n",
    "if not os.path.exists(CHUNKS_FILE):\n",
    "    raise FileNotFoundError(f\"Missing {CHUNKS_FILE}. Run Notebook 01 first!\")\n",
    "\n",
    "print(f\"Using chunks file: {CHUNKS_FILE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6235f1",
   "metadata": {},
   "source": [
    "# 2 Load Chunks from JSONL\n",
    "We'll load all chunk records from the saved file.\n",
    "Each chunk has: source, chunk_id, text, and type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f326e986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1073 text chunks.\n",
      "Example chunk:\n",
      "{\n",
      "  \"id\": \"test_chunk0\",\n",
      "  \"source\": \"./data/test.pdf\",\n",
      "  \"chunk\": \"The Journey A Digital and Societ\n"
     ]
    }
   ],
   "source": [
    "def load_chunks(file_path: str) -> List[Dict]:\n",
    "    \"\"\"Load a JSONL file into a Python list of dictionaries.\"\"\"\n",
    "    chunks = []\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            chunks.append(json.loads(line))\n",
    "    return chunks\n",
    "\n",
    "# --- Load and preview ---\n",
    "all_chunks = load_chunks(CHUNKS_FILE)\n",
    "print(f\"Loaded {len(all_chunks)} text chunks.\")\n",
    "print(\"Example chunk:\")\n",
    "print(json.dumps(all_chunks[0], indent=2)[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224c062a",
   "metadata": {},
   "source": [
    "# 3 Generate Embeddings\n",
    "\n",
    "We'll use an open-source model from Hugging Face\n",
    "(SentenceTransformers) to create vector embeddings.\n",
    "These embeddings represent semantic meaning numerically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06e5bca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model: BAAI/bge-m3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04c7316fa2b4481a88a0c80bace9446a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 30 files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding text chunks with BGE-M3:   0%|          | 0/1073 [00:00<?, ?it/s]You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "Encoding text chunks with BGE-M3: 100%|██████████| 1073/1073 [07:13<00:00,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished generating corrected BGE-M3 embeddings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "##--- Generate BGE-M3 Embeddings ---\n",
    "##--- Modified from using all-MiniLM-L6-v2 to BGE-M3 ---\n",
    "\n",
    "from FlagEmbedding import BGEM3FlagModel\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "model_name = \"BAAI/bge-m3\"\n",
    "print(f\"Loading embedding model: {model_name}\")\n",
    "\n",
    "embedder = BGEM3FlagModel(model_name, use_fp16=False)\n",
    "\n",
    "for chunk in tqdm(all_chunks, desc=\"Encoding text chunks with BGE-M3\"):\n",
    "    outputs = embedder.encode(\n",
    "        chunk[\"chunk\"],\n",
    "        max_length=8192,\n",
    "        return_dense=True,\n",
    "        return_sparse=False,\n",
    "        return_colbert_vecs=False\n",
    "    )\n",
    "\n",
    "    # FIX: dense_vecs IS ALREADY the full embedding vector\n",
    "    embedding = outputs[\"dense_vecs\"]  # shape (1024,)\n",
    "\n",
    "    # Normalize (recommended for cosine search)\n",
    "    norm = np.linalg.norm(embedding)\n",
    "    if norm > 0:\n",
    "        embedding = embedding / norm\n",
    "\n",
    "    chunk[\"embedding\"] = embedding.tolist()\n",
    "\n",
    "print(\"Finished generating corrected BGE-M3 embeddings.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85e2a12",
   "metadata": {},
   "source": [
    "# 4 Connect or Initialize Qdrant\n",
    "\n",
    "This cell connects to a local Qdrant instance.\n",
    "You can run Qdrant locally using Docker:\n",
    "  docker run -p 6333:6333 qdrant/qdrant\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d797dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26462/477041369.py:11: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n",
      "  client.recreate_collection(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection 'enterprise_docs' recreated with 1024-dim vectors for BGE-M3.\n"
     ]
    }
   ],
   "source": [
    "# Create a Qdrant client connected to your local instance\n",
    "client = QdrantClient(\"http://localhost:6333\")\n",
    "\n",
    "# Define collection name for our embeddings and metadata\n",
    "COLLECTION_NAME = \"enterprise_docs\"\n",
    "\n",
    "# BGE-M3 produces 1024-dimensional embeddings\n",
    "VECTOR_DIM = 1024\n",
    "\n",
    "# Recreate the collection for BGE-M3\n",
    "client.recreate_collection(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    vectors_config=rest.VectorParams(\n",
    "        size=VECTOR_DIM,            # Correct dim for BGE-M3\n",
    "        distance=rest.Distance.COSINE\n",
    "    )\n",
    ")\n",
    "\n",
    "print(f\"Collection '{COLLECTION_NAME}' recreated with {VECTOR_DIM}-dim vectors for BGE-M3.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712c819a",
   "metadata": {},
   "source": [
    "# 5 Upload Embeddings and Metadata\n",
    "\n",
    "We'll push each chunk’s vector and metadata to Qdrant.\n",
    "This enables semantic search later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "738f5825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 1073 chunks to collection 'enterprise_docs'.\n"
     ]
    }
   ],
   "source": [
    "# Prepare points for Qdrant (each point = one vector + metadata)\n",
    "points = []\n",
    "for idx, chunk in enumerate(all_chunks):\n",
    "    points.append(\n",
    "        rest.PointStruct(\n",
    "            id=idx,  # unique ID for this chunk\n",
    "            vector=chunk[\"embedding\"],  # the embedding vector\n",
    "            payload={  # additional metadata\n",
    "                \"source\": chunk[\"source\"],\n",
    "                \"chunk_id\": chunk[\"id\"],\n",
    "                \"text\": chunk[\"chunk\"],\n",
    "                \"type\": chunk.get(\"type\", \"unknown\")\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "\n",
    "# --- Upload to Qdrant ---\n",
    "client.upsert(collection_name=COLLECTION_NAME, points=points)\n",
    "\n",
    "print(f\"Uploaded {len(points)} chunks to collection '{COLLECTION_NAME}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfbcd96",
   "metadata": {},
   "source": [
    "# 6 Test Semantic Search\n",
    "\n",
    "Let's try asking a question, embed it, and search similar content\n",
    "from our stored chunks in Qdrant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4411549a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: What does 6G offer?\n",
      "\n",
      "Result 1 — Score: 0.6629\n",
      "Source: ./data/test.pdf\n",
      "Text snippet: . The 6 G vision is to create a seamless reality where the physical and digital worlds, so far separated, are converged. This will enable seamless movement in a cyberphysical continuum of a connected physical world of senses, actions, and experiences, and its programmable digital representation. Wit...\n",
      "--------------------------------------------------------------------------------\n",
      "Result 2 — Score: 0.6524\n",
      "Source: ./data/test.pdf\n",
      "Text snippet: . II and overviewing the use cases (UC) that are expected to drive a digital and societal revolution in Sec. III. This is followed by introducing the paradigm shifts that formulate an evolved network architecture in Sec. IV. In Sec. V, we highlight the main 6 G technologies needed to realize the vis...\n",
      "--------------------------------------------------------------------------------\n",
      "Result 3 — Score: 0.6511\n",
      "Source: ./data/test.pdf\n",
      "Text snippet: . In addition, the vision of 6 G is to also create more humanfriendly, sustainable, and efficient communities. This requires networks that guarantee worldwide digital inclusion to support a wide range of elements, end-to-end (E 2 E) life-cycle tracking to reduce waste and automate recycling, resourc...\n",
      "--------------------------------------------------------------------------------\n",
      "Result 4 — Score: 0.6384\n",
      "Source: ./data/test.pdf\n",
      "Text snippet: . This article presented a novel perspective on the 6 G vision and the evolution of mobile networks towards this vision. To this end, we presented the 6 G promise, portrayed through four driving UCs. To achieve the discussed promise, we introduced our vision of the six architectural pillars of 6 G n...\n",
      "--------------------------------------------------------------------------------\n",
      "Result 5 — Score: 0.6373\n",
      "Source: ./data/test.pdf\n",
      "Text snippet: . M. Tatipamula is with Ericsson Silicon Valley, Santa Clara, CA 95054, USA (e-mail: mallik.tatipamula@ericsson.com). 3202 nu J 6 ]IN.sc[ 2 v 23800.6032:vi Xra 1 Towards 6 G: evolution in the Making atipamula, and Muhammad Ali Imran systems toward their limits within 10 years of their launch and cal...\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# --- Example user query ---\n",
    "query = \"What does 6G offer?\"\n",
    "\n",
    "# Generate embedding for the query using BGE-M3\n",
    "q_out = embedder.encode(\n",
    "    query,\n",
    "    max_length=8192,\n",
    "    return_dense=True,\n",
    "    return_sparse=False,\n",
    "    return_colbert_vecs=False\n",
    ")\n",
    "\n",
    "# Extract dense embedding\n",
    "query_vector = q_out[\"dense_vecs\"]\n",
    "\n",
    "# Normalize (recommended for cosine searches)\n",
    "import numpy as np\n",
    "norm = np.linalg.norm(query_vector)\n",
    "if norm > 0:\n",
    "    query_vector = query_vector / norm\n",
    "\n",
    "query_vector = query_vector.tolist()\n",
    "\n",
    "# --- Perform vector search ---\n",
    "search_results = client.query_points(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    query=query_vector,\n",
    "    limit=5\n",
    ")\n",
    "\n",
    "# --- Display results ---\n",
    "print(f\"\\nQuery: {query}\\n\")\n",
    "for i, hit in enumerate(search_results.points):\n",
    "    print(f\"Result {i+1} — Score: {hit.score:.4f}\")\n",
    "    print(f\"Source: {hit.payload.get('source')}\")\n",
    "    print(f\"Text snippet: {hit.payload.get('text')[:300]}...\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79ec091",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
